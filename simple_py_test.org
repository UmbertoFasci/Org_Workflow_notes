#+title: Simple_py_test


#+begin_src python :session :results output
print("Hello World")
#+end_src

#+RESULTS:
: Hello World

#+begin_src python :session :results output
import tensorflow as tf
print(tf.__version__)
#+end_src

#+RESULTS:
: 2.9.0

Clearly, org-babel is identifying the proper python environment which I have specified through the ~conda-env-activate-path~ command.
However, I face major issues when I begin a model fit sequence:

<#+begin_quote
tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
#+end_quote


* Test with tensorflow-metal

This is a conda env which was been configured and installed following the official methods for MacOS M1 devices.

Following the beginner tutorial provided by TensorFlow I will test whether or not this is functioning as it should.

#+begin_src python :session :results output
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
#+end_src

#+RESULTS:

#+begin_src python :session :results output
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
#+end_src

#+RESULTS:
: Metal device set to: Apple M1 Max
:
: systemMemory: 32.00 GB
: maxCacheSize: 10.67 GB
:
: 2023-03-02 21:59:17.662690: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
: 2023-03-02 21:59:17.663023: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)

#+begin_src python :session :results output value
predictions = model(x_train[:1]).numpy()
predictions
#+end_src

#+RESULTS:
| 0.06667423 | 0.2847122 | -0.38781705 | -0.30231008 | -0.18481252 | 0.85817015 | -0.35114557 | -0.03586156 | 0.01792535 | -0.90480185 |


#+begin_src python :session :results output value
tf.nn.softmax(predictions).numpy()
#+end_src

#+RESULTS:
| 0.10586323 | 0.13165514 | 0.06719889 | 0.07319767 | 0.08232387 | 0.23360787 | 0.06970891 | 0.09554642 | 0.10082629 | 0.04007177 |


#+begin_src python :session :results output
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
#+end_src

#+RESULTS:

#+begin_src python :session :results output value
loss_fn(y_train[:1], predictions).numpy()
#+end_src

#+RESULTS:
: 1.4541112


#+begin_src python :session :results output
model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])
#+end_src

#+RESULTS:

#+begin_src python :session :results output silent
model.fit(x_train, y_train, epochs=5)
#+end_src

With downgrading tensorflow-macos and tensorflow-metal I was able to finally have an expected model fit sequence!
